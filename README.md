# 🧠 Persona-Driven Document Intelligence Backend (Round 1B)

This repository contains the backend code for the _“Connecting the Dots”_ challenge Round 1B. It performs persona-driven document analysis and semantic ranking on PDF files.

---

## Important Notice about the Model

The core embedding model **`intfloat/e5-small-v2`** (used for semantic analysis) is **not included** in this repo due to its large size (~128 MB), which exceeds GitHub’s file size limits.

---

## How to Get the Model

Before running the backend or building the Docker image, you need to download the model manually by running:

python download_model.py

---

## NOTE: 
Once the model is downloaded, the entire project runs completely offline.
The model file resides locally and is used directly by the backend to process PDFs without any internet connection.

--- 


 ## Folder Structure

 doc_int/
├── input/                   # Folder for input PDF files
├── model/                   # Embedding model and semantic logic
├── extractor/               # PDF text and OCR extraction modules
├── main.py                  # Backend entry point
├── download_model.py        # Script to download the large embedding model
├── Dockerfile               # Docker build instructions
├── requirements.txt         # Python dependencies
├── challenge1b_output.json  # Output file generated by backend

## Docker Execution Instructions :

# 1. Build the Docker image (Linux/AMD64)
docker build --platform linux/amd64 -t docintelligence:1b .

# 2. Run the container
docker run --rm -v $(pwd)/input:/app/input -v $(pwd)/challenge1b_output.json:/app/challenge1b_output.json docintelligence:1b

On Windows PowerShell:
docker run --rm -v ${PWD}/input:/app/input -v ${PWD}/challenge1b_output.json:/app/challenge1b_output.json docintelligence:1b






