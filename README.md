# 🧠 Persona-Driven Document Intelligence Backend (Round 1B)

This repository contains the backend code for the _“Connecting the Dots”_ challenge Round 1B. It performs persona-driven document analysis and semantic ranking on PDF files.

---

## Important Notice about the Model

The core embedding model **`intfloat/e5-small-v2`** (used for semantic analysis) is **not included** in this repo due to its large size (~128 MB), which exceeds GitHub’s file size limits.

---

## How to Get the Model

Before running the backend or building the Docker image, you need to download the model manually by running:

python download_model.py

---

## NOTE: 
Once the model is downloaded, the entire project runs completely offline.
The model file resides locally and is used directly by the backend to process PDFs without any internet connection.

--- 

## Docker Image

A Docker image is also provided to run the backend easily.
The Dockerfile is included in this repo.
The Docker container bundles the model, ensuring offline execution.

 ## Folder Structure

 doc_int/
├── input/                   # Folder for input PDF files
├── model/                   # Embedding model and semantic logic
├── extractor/               # PDF text and OCR extraction modules
├── main.py                  # Backend entry point
├── download_model.py        # Script to download the large embedding model
├── Dockerfile               # Docker build instructions
├── requirements.txt         # Python dependencies
├── challenge1b_output.json  # Output file generated by backend

## Build the Docker image :
docker build --platform linux/amd64 -t docintelligence:1b .


